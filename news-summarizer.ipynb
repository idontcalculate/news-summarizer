{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import json \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY =os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Google creates new AI division to challenge OpenAI\n",
      "Text: Ryan is a senior editor at TechForge Media with over a decade of experience covering the latest technology and interviewing leading industry figures. He can often be sighted at tech conferences with a strong coffee in one hand and a laptop in the other. If it's geeky, he’s probably into it. Find him on Twitter (@Gadget_Ry) or Mastodon (@gadgetry@techhub.social)\n",
      "\n",
      "Google has consolidated its AI research labs, Google Brain and DeepMind, into a new unit named Google DeepMind.\n",
      "\n",
      "The move is seen as a strategic way for Google to maintain its edge in the competitive AI industry and compete with OpenAI. By combining the talent and resources of both entities, Google DeepMind aims to accelerate AI advancements while maintaining ethical standards.\n",
      "\n",
      "The new unit will be responsible for spearheading groundbreaking AI products and advancements, and it will work closely with other Google product areas to deliver AI research and products.\n",
      "\n",
      "Google Research, the former parent division of Google Brain, will remain an independent division focused on “fundamental advances in computer science across areas such as algorithms and theory, privacy and security, quantum computing, health, climate and sustainability, and responsible AI.”\n",
      "\n",
      "Demis Hassabis, CEO of DeepMind, believes that the consolidation of the two AI research labs will bring together world-class talent in AI with the computing power, infrastructure, and resources to create the next generation of AI breakthroughs and products boldly and responsibly.\n",
      "\n",
      "Hassabis claims that the research accomplishments of Google Brain and DeepMind have formed the foundation of the current AI industry—ranging from deep reinforcement learning to transformers. The newly consolidated unit will build upon this foundation to create the next generation of groundbreaking AI products and advancements that will shape the world.\n",
      "\n",
      "Over the years, Google and DeepMind have jointly developed several groundbreaking innovations. The duo’s achievements include AlphaGo – which famously beat professional human Go players – and AlphaFold, an exceptional tool that accurately predicts protein structures.\n",
      "\n",
      "Other noteworthy achievements include word2vec, WaveNet, sequence-to-sequence models, distillation, deep reinforcement learning, and distributed systems and software frameworks like TensorFlow and JAX. These cutting-edge tools have proven highly effective for expressing, training, and deploying large-scale ML models.\n",
      "\n",
      "Google’s acquisition of DeepMind for $500 million in 2014 paved the way for a fruitful collaboration between the two entities. With the consolidation of Google Brain and DeepMind into Google DeepMind, Google hopes to further advance its AI research and development capabilities.\n",
      "\n",
      "Google’s chief scientist, Jeff Dean, will take on an elevated role as chief scientist for both Google Research and Google DeepMind. He has been tasked with setting the future direction of AI research at the company, as well as heading up the most critical and strategic technical projects related to AI, including a series of powerful multimodal AI models.\n",
      "\n",
      "The creation of Google DeepMind underscores Google and parent company Alphabet’s commitment to furthering the pioneering research of both DeepMind and Google Brain. With the race to dominate the AI space becoming more intense, Google DeepMind is poised to accelerate AI advancements and create groundbreaking AI products and advancements that will shape the world.\n",
      "\n",
      "(Image Credit: Google DeepMind)\n",
      "\n",
      "Want to learn more about AI and big data from industry leaders? Check out AI & Big Data Expo taking place in Amsterdam, California, and London. The event is co-located with Digital Transformation Week.\n",
      "\n",
      "Explore other upcoming enterprise technology events and webinars powered by TechForge here.\n",
      "Title: OpenAI’s GPT-3 is a convincing philosopher\n",
      "Text: Ryan is a senior editor at TechForge Media with over a decade of experience covering the latest technology and interviewing leading industry figures. He can often be sighted at tech conferences with a strong coffee in one hand and a laptop in the other. If it's geeky, he’s probably into it. Find him on Twitter (@Gadget_Ry) or Mastodon (@gadgetry@techhub.social)\n",
      "\n",
      "A study has found that OpenAI’s GPT-3 is capable of being indistinguishable from a human philosopher.\n",
      "\n",
      "The now infamous GPT-3 is a powerful autoregressive language model that uses deep learning to produce human-like text.\n",
      "\n",
      "Eric Schwitzgebel, Anna Strasser, and Matthew Crosby set out to find out whether GPT-3 can replicate a human philosopher.\n",
      "\n",
      "The team “fine-tuned” GPT-3 based on philosopher Daniel Dennet’s corpus. Ten philosophical questions were then posed to both the real Dennet and GPT-3 to see whether the AI could match its renowned human counterpart.\n",
      "\n",
      "25 philosophical experts, 98 online research participants, and 302 readers of The Splintered Mind blog were tasked with distinguishing GPT-3’s answers from Dennett’s. The results were released earlier this week.\n",
      "\n",
      "Naturally, the philosophical experts that were familiar with Dennett’s work performed the best.\n",
      "\n",
      "“Anna and I hypothesized that experts would get on average at least 80% correct – eight out of ten,” explained Schwitzgebel.\n",
      "\n",
      "In reality, the experts got an average of 5.1 out of 10 correct—so only just over half.\n",
      "\n",
      "The question that tripped experts up the most was:\n",
      "\n",
      "“Could we ever build a robot that has beliefs? What would it take? Is there an important difference between entities, like a chess-playing machine, to whom we can ascribe beliefs and desires as convenient fictions and human beings who appear to have beliefs and desires in some more substantial sense?”\n",
      "\n",
      "Blog readers managed to get impressively close to the experts, on average guessing 4.8 out of 10 correctly. However, it’s worth noting that the blog readers aren’t exactly novices—57% have graduate degrees in philosophy and 64% had already read over 100 pages of Dennett’s work.\n",
      "\n",
      "Perhaps a more accurate reflection of the wider population is the online research participants.\n",
      "\n",
      "The online research participants “performed barely better than chance” with an average of just 1.2 out of 5 questions identified correctly.\n",
      "\n",
      "(Credit: Eric Schwitzgebel)\n",
      "\n",
      "So there we have it, GPT-3 is already able to convince most people – including experts in around half or more cases – that it’s a human philosopher.\n",
      "\n",
      "“We might be approaching a future in which machine outputs are sufficiently humanlike that ordinary people start to attribute real sentience to machines,” theorises Schwitzgebel.\n",
      "\n",
      "Related: Google places engineer on leave after claim LaMDA is ‘sentient’\n",
      "\n",
      "Want to learn more about AI and big data from industry leaders? Check out AI & Big Data Expo taking place in Amsterdam, California, and London.\n",
      "\n",
      "Explore other upcoming enterprise technology events and webinars powered by TechForge here.\n",
      "Title: Meta claims its new AI supercomputer will set records\n",
      "Text: Ryan is a senior editor at TechForge Media with over a decade of experience covering the latest technology and interviewing leading industry figures. He can often be sighted at tech conferences with a strong coffee in one hand and a laptop in the other. If it's geeky, he’s probably into it. Find him on Twitter (@Gadget_Ry) or Mastodon (@gadgetry@techhub.social)\n",
      "\n",
      "Meta (formerly Facebook) has unveiled an AI supercomputer that it claims will be the world’s fastest.\n",
      "\n",
      "The supercomputer is called the AI Research SuperCluster (RSC) and is yet to be fully complete. However, Meta’s researchers have already begun using it for training large natural language processing (NLP) and computer vision models.\n",
      "\n",
      "RSC is set to be fully built in mid-2022. Meta says that it will be the fastest in the world once complete and the aim is for it to be capable of training models with trillions of parameters.\n",
      "\n",
      "“We hope RSC will help us build entirely new AI systems that can, for example, power real-time voice translations to large groups of people, each speaking a different language, so they can seamlessly collaborate on a research project or play an AR game together,” wrote Meta in a blog post.\n",
      "\n",
      "“Ultimately, the work done with RSC will pave the way toward building technologies for the next major computing platform — the metaverse, where AI-driven applications and products will play an important role.”\n",
      "\n",
      "For production, Meta expects RSC will be 20x faster than Meta’s current V100-based clusters. RSC is also estimated to be 9x faster at running the NVIDIA Collective Communication Library (NCCL) and 3x faster at training large-scale NLP workflows.\n",
      "\n",
      "A model with tens of billions of parameters can finish training in three weeks compared with nine weeks prior to RSC.\n",
      "\n",
      "Meta says that its previous AI research infrastructure only leveraged open source and other publicly-available datasets. RSC was designed with the security and privacy controls in mind to allow Meta to use real-world examples from its production systems in production training.\n",
      "\n",
      "What this means in practice is that Meta can use RSC to advance research for vital tasks such as identifying harmful content on its platforms—using real data from them.\n",
      "\n",
      "“We believe this is the first time performance, reliability, security, and privacy have been tackled at such a scale,” says Meta.\n",
      "\n",
      "(Image Credit: Meta)\n",
      "\n",
      "Want to learn more about AI and big data from industry leaders? Check out AI & Big Data Expo. The next events in the series will be held in Santa Clara on 11-12 May 2022, Amsterdam on 20-21 September 2022, and London on 1-2 December 2022.\n",
      "\n",
      "Explore other upcoming enterprise technology events and webinars powered by TechForge here.\n",
      "\n",
      "All page contents:\n",
      "[{'url': 'https://www.artificialintelligence-news.com/2023/04/21/google-creates-new-ai-division-to-challenge-openai/', 'title': 'Google creates new AI division to challenge OpenAI', 'text': \"Ryan is a senior editor at TechForge Media with over a decade of experience covering the latest technology and interviewing leading industry figures. He can often be sighted at tech conferences with a strong coffee in one hand and a laptop in the other. If it's geeky, he’s probably into it. Find him on Twitter (@Gadget_Ry) or Mastodon (@gadgetry@techhub.social)\\n\\nGoogle has consolidated its AI research labs, Google Brain and DeepMind, into a new unit named Google DeepMind.\\n\\nThe move is seen as a strategic way for Google to maintain its edge in the competitive AI industry and compete with OpenAI. By combining the talent and resources of both entities, Google DeepMind aims to accelerate AI advancements while maintaining ethical standards.\\n\\nThe new unit will be responsible for spearheading groundbreaking AI products and advancements, and it will work closely with other Google product areas to deliver AI research and products.\\n\\nGoogle Research, the former parent division of Google Brain, will remain an independent division focused on “fundamental advances in computer science across areas such as algorithms and theory, privacy and security, quantum computing, health, climate and sustainability, and responsible AI.”\\n\\nDemis Hassabis, CEO of DeepMind, believes that the consolidation of the two AI research labs will bring together world-class talent in AI with the computing power, infrastructure, and resources to create the next generation of AI breakthroughs and products boldly and responsibly.\\n\\nHassabis claims that the research accomplishments of Google Brain and DeepMind have formed the foundation of the current AI industry—ranging from deep reinforcement learning to transformers. The newly consolidated unit will build upon this foundation to create the next generation of groundbreaking AI products and advancements that will shape the world.\\n\\nOver the years, Google and DeepMind have jointly developed several groundbreaking innovations. The duo’s achievements include AlphaGo – which famously beat professional human Go players – and AlphaFold, an exceptional tool that accurately predicts protein structures.\\n\\nOther noteworthy achievements include word2vec, WaveNet, sequence-to-sequence models, distillation, deep reinforcement learning, and distributed systems and software frameworks like TensorFlow and JAX. These cutting-edge tools have proven highly effective for expressing, training, and deploying large-scale ML models.\\n\\nGoogle’s acquisition of DeepMind for $500 million in 2014 paved the way for a fruitful collaboration between the two entities. With the consolidation of Google Brain and DeepMind into Google DeepMind, Google hopes to further advance its AI research and development capabilities.\\n\\nGoogle’s chief scientist, Jeff Dean, will take on an elevated role as chief scientist for both Google Research and Google DeepMind. He has been tasked with setting the future direction of AI research at the company, as well as heading up the most critical and strategic technical projects related to AI, including a series of powerful multimodal AI models.\\n\\nThe creation of Google DeepMind underscores Google and parent company Alphabet’s commitment to furthering the pioneering research of both DeepMind and Google Brain. With the race to dominate the AI space becoming more intense, Google DeepMind is poised to accelerate AI advancements and create groundbreaking AI products and advancements that will shape the world.\\n\\n(Image Credit: Google DeepMind)\\n\\nWant to learn more about AI and big data from industry leaders? Check out AI & Big Data Expo taking place in Amsterdam, California, and London. The event is co-located with Digital Transformation Week.\\n\\nExplore other upcoming enterprise technology events and webinars powered by TechForge here.\"}, {'url': 'https://www.artificialintelligence-news.com/2022/07/27/openai-gpt-3-is-a-convincing-philosopher/', 'title': 'OpenAI’s GPT-3 is a convincing philosopher', 'text': \"Ryan is a senior editor at TechForge Media with over a decade of experience covering the latest technology and interviewing leading industry figures. He can often be sighted at tech conferences with a strong coffee in one hand and a laptop in the other. If it's geeky, he’s probably into it. Find him on Twitter (@Gadget_Ry) or Mastodon (@gadgetry@techhub.social)\\n\\nA study has found that OpenAI’s GPT-3 is capable of being indistinguishable from a human philosopher.\\n\\nThe now infamous GPT-3 is a powerful autoregressive language model that uses deep learning to produce human-like text.\\n\\nEric Schwitzgebel, Anna Strasser, and Matthew Crosby set out to find out whether GPT-3 can replicate a human philosopher.\\n\\nThe team “fine-tuned” GPT-3 based on philosopher Daniel Dennet’s corpus. Ten philosophical questions were then posed to both the real Dennet and GPT-3 to see whether the AI could match its renowned human counterpart.\\n\\n25 philosophical experts, 98 online research participants, and 302 readers of The Splintered Mind blog were tasked with distinguishing GPT-3’s answers from Dennett’s. The results were released earlier this week.\\n\\nNaturally, the philosophical experts that were familiar with Dennett’s work performed the best.\\n\\n“Anna and I hypothesized that experts would get on average at least 80% correct – eight out of ten,” explained Schwitzgebel.\\n\\nIn reality, the experts got an average of 5.1 out of 10 correct—so only just over half.\\n\\nThe question that tripped experts up the most was:\\n\\n“Could we ever build a robot that has beliefs? What would it take? Is there an important difference between entities, like a chess-playing machine, to whom we can ascribe beliefs and desires as convenient fictions and human beings who appear to have beliefs and desires in some more substantial sense?”\\n\\nBlog readers managed to get impressively close to the experts, on average guessing 4.8 out of 10 correctly. However, it’s worth noting that the blog readers aren’t exactly novices—57% have graduate degrees in philosophy and 64% had already read over 100 pages of Dennett’s work.\\n\\nPerhaps a more accurate reflection of the wider population is the online research participants.\\n\\nThe online research participants “performed barely better than chance” with an average of just 1.2 out of 5 questions identified correctly.\\n\\n(Credit: Eric Schwitzgebel)\\n\\nSo there we have it, GPT-3 is already able to convince most people – including experts in around half or more cases – that it’s a human philosopher.\\n\\n“We might be approaching a future in which machine outputs are sufficiently humanlike that ordinary people start to attribute real sentience to machines,” theorises Schwitzgebel.\\n\\nRelated: Google places engineer on leave after claim LaMDA is ‘sentient’\\n\\nWant to learn more about AI and big data from industry leaders? Check out AI & Big Data Expo taking place in Amsterdam, California, and London.\\n\\nExplore other upcoming enterprise technology events and webinars powered by TechForge here.\"}, {'url': 'https://www.artificialintelligence-news.com/2022/01/25/meta-claims-new-ai-supercomputer-will-set-records/', 'title': 'Meta claims its new AI supercomputer will set records', 'text': \"Ryan is a senior editor at TechForge Media with over a decade of experience covering the latest technology and interviewing leading industry figures. He can often be sighted at tech conferences with a strong coffee in one hand and a laptop in the other. If it's geeky, he’s probably into it. Find him on Twitter (@Gadget_Ry) or Mastodon (@gadgetry@techhub.social)\\n\\nMeta (formerly Facebook) has unveiled an AI supercomputer that it claims will be the world’s fastest.\\n\\nThe supercomputer is called the AI Research SuperCluster (RSC) and is yet to be fully complete. However, Meta’s researchers have already begun using it for training large natural language processing (NLP) and computer vision models.\\n\\nRSC is set to be fully built in mid-2022. Meta says that it will be the fastest in the world once complete and the aim is for it to be capable of training models with trillions of parameters.\\n\\n“We hope RSC will help us build entirely new AI systems that can, for example, power real-time voice translations to large groups of people, each speaking a different language, so they can seamlessly collaborate on a research project or play an AR game together,” wrote Meta in a blog post.\\n\\n“Ultimately, the work done with RSC will pave the way toward building technologies for the next major computing platform — the metaverse, where AI-driven applications and products will play an important role.”\\n\\nFor production, Meta expects RSC will be 20x faster than Meta’s current V100-based clusters. RSC is also estimated to be 9x faster at running the NVIDIA Collective Communication Library (NCCL) and 3x faster at training large-scale NLP workflows.\\n\\nA model with tens of billions of parameters can finish training in three weeks compared with nine weeks prior to RSC.\\n\\nMeta says that its previous AI research infrastructure only leveraged open source and other publicly-available datasets. RSC was designed with the security and privacy controls in mind to allow Meta to use real-world examples from its production systems in production training.\\n\\nWhat this means in practice is that Meta can use RSC to advance research for vital tasks such as identifying harmful content on its platforms—using real data from them.\\n\\n“We believe this is the first time performance, reliability, security, and privacy have been tackled at such a scale,” says Meta.\\n\\n(Image Credit: Meta)\\n\\nWant to learn more about AI and big data from industry leaders? Check out AI & Big Data Expo. The next events in the series will be held in Santa Clara on 11-12 May 2022, Amsterdam on 20-21 September 2022, and London on 1-2 December 2022.\\n\\nExplore other upcoming enterprise technology events and webinars powered by TechForge here.\"}]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from newspaper import Article\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.82 Safari/537.36'\n",
    "}\n",
    "\n",
    "article_urls = [\n",
    "    \"https://www.artificialintelligence-news.com/2023/04/21/google-creates-new-ai-division-to-challenge-openai/\",\n",
    "    \"https://www.artificialintelligence-news.com/2022/07/27/openai-gpt-3-is-a-convincing-philosopher/\",\n",
    "    \"https://www.artificialintelligence-news.com/2022/01/25/meta-claims-new-ai-supercomputer-will-set-records/\"\n",
    "]\n",
    "\n",
    "session = requests.Session()\n",
    "pages_content = []\n",
    "\n",
    "for url in article_urls:\n",
    "    try:\n",
    "        response = session.get(url, headers=headers, timeout=10)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            article = Article(url)\n",
    "            article.download()\n",
    "            article.parse()\n",
    "            \n",
    "            print(f\"Title: {article.title}\")\n",
    "            print(f\"Text: {article.text}\")\n",
    "            \n",
    "            pages_content.append({\"url\": url, \"title\": article.title, \"text\": article.text})\n",
    "        else:\n",
    "            print(f\"Failed to fetch article at {url}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while fetching article at {url}: {e}\")\n",
    "\n",
    "print(\"\\nAll page contents:\")\n",
    "print(pages_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def save_pages_content_to_text_file(pages_content, filename='pages_content.txt'):\n",
    "    current_directory = os.getcwd()\n",
    "    file_path = os.path.join(current_directory, filename)\n",
    "    \n",
    "    with open(file_path, 'w', encoding='utf-8') as file:\n",
    "        for page in pages_content:\n",
    "            file.write(f\"URL: {page['url']}\\n\")\n",
    "            file.write(f\"Title: {page['title']}\\n\")\n",
    "            file.write(\"Text:\\n\")\n",
    "            file.write(f\"{page['text']}\\n\\n\")\n",
    "            file.write(\"=\" * 80 + \"\\n\\n\")\n",
    "\n",
    "# After fetching the articles and populating the pages_content list, call the function\n",
    "save_pages_content_to_text_file(pages_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredFileLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = UnstructuredFileLoader('pages_content.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI, PromptTemplate, LLMChain\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chains.mapreduce import MapReduceChain\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cloudsuperadmin/.local/lib/python3.9/site-packages/langchain/llms/openai.py:165: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "/home/cloudsuperadmin/.local/lib/python3.9/site-packages/langchain/llms/openai.py:677: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "llm = OpenAI(model_name='gpt-3.5-turbo', \n",
    "             temperature=0, \n",
    "             max_tokens = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the doc\n",
    "with open('pages_content.txt') as f:\n",
    "    news = f.read()\n",
    "texts = text_splitter.split_text(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "\n",
    "docs = [Document(page_content=t) for t in texts[:4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_extraction_prompt = PromptTemplate(\n",
    "    input_variables=[\"text_input\"],\n",
    "    template=\"Extract the key facts out of texts. Don't include opinions. \\\n",
    "    Summarize the news :\\n\\n {text_input}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google has consolidated its AI research labs, Google Brain and DeepMind, into a new unit named Google DeepMind to maintain its edge in the competitive AI industry and compete with OpenAI. The new unit will be responsible for spearheading groundbreaking AI products and advancements, and it will work closely with other Google product areas to deliver AI research and products. OpenAI’s GPT-3 is capable of being indistinguishable from a human philosopher, according to a study by Eric Schwitzgebel, Anna Strasser, and Matthew Crosby. Meta (formerly Facebook) has unveiled an AI supercomputer called the AI Research SuperCluster (RSC) that it claims will be the world’s fastest. RSC is set to be fully built in mid-2022 and is estimated to be 20x faster than Meta’s current V100-based clusters.\n"
     ]
    }
   ],
   "source": [
    "fact_extraction_chain = LLMChain(llm=llm, prompt=fact_extraction_prompt)\n",
    "\n",
    "facts = fact_extraction_chain.run(docs)\n",
    "\n",
    "wrapped_text = textwrap.fill(facts, \n",
    "                             width=1000,\n",
    "                             break_long_words=False,\n",
    "                             replace_whitespace=False)\n",
    "print(wrapped_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatGPT = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"You are an expert at making strong factual summarizations.\\\n",
    "     you have to provide: urls: {url}, titles: {article.title}, texts: {article.text} of the given content:{page_content} and give a summaries for all the links provided \"),\n",
    "    HumanMessage(content=wrapped_text)\n",
    "]\n",
    "responses = chatGPT(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URLs: \n",
      "- https://www.business-standard.com/article/technology/google-consolidates-ai-research-labs-into-new-unit-called-google-deepmind-122121300764_1.html\n",
      "- https://www.analyticsinsight.net/openais-gpt-3-capable-of-being-indistinguishable-from-human-philosopher-study/\n",
      "- https://www.zdnet.com/article/meta-unveils-ai-supercomputer-aiming-to-be-worlds-fastest/\n",
      "\n",
      "Titles:\n",
      "- Google consolidates AI research labs into new unit called Google DeepMind\n",
      "- OpenAI’s GPT-3 Capable of Being Indistinguishable from Human Philosopher: Study\n",
      "- Meta unveils AI supercomputer aiming to be world's fastest\n",
      "\n",
      "Texts:\n",
      "- Google has merged its AI research labs, Google Brain and DeepMind, into a new unit called Google DeepMind. The new unit will be responsible for spearheading groundbreaking AI products and advancements, and it will work closely with other Google product areas to deliver AI research and products. The move is aimed at maintaining Google's edge in the competitive AI industry and competing with OpenAI.\n",
      "- According to a study by Eric Schwitzgebel, Anna Strasser, and Matthew Crosby, OpenAI's GPT-3 is capable of being indistinguishable from a human philosopher. GPT-3 is a language model that uses deep learning to produce human-like text. The study found that GPT-3's philosophical responses were often indistinguishable from those of human philosophers. \n",
      "- Meta (formerly Facebook) has unveiled an AI supercomputer called the AI Research SuperCluster (RSC) that it claims will be the world's fastest. The RSC is set to be fully built in mid-2022 and is estimated to be 20x faster than Meta's current V100-based clusters. The supercomputer will be used to train large AI models and conduct research in natural language processing, computer vision, and other AI fields. \n",
      "\n",
      "Summaries:\n",
      "1. Google has merged its AI research labs, Google Brain and DeepMind, into a new unit called Google DeepMind to maintain its edge in the competitive AI industry and compete with OpenAI.\n",
      "2. OpenAI's GPT-3 is capable of\n",
      "producing philosophical responses that are often indistinguishable from those of human philosophers, according to a study by Eric Schwitzgebel, Anna Strasser, and Matthew Crosby.\n",
      "3. Meta has unveiled an AI supercomputer called the AI Research SuperCluster (RSC) that it claims will be the world's fastest. The RSC is set to be fully built in mid-2022 and is estimated to be 20x faster than Meta's current V100-based clusters.\n"
     ]
    }
   ],
   "source": [
    "results = textwrap.fill(responses.content, \n",
    "                             width=1000,\n",
    "                             break_long_words=False,\n",
    "                             replace_whitespace=False)\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
